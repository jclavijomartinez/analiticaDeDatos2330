{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64303609-a9f7-45fa-9af6-d07238a3d69b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Proyecto Final Analítica de Datos\n",
    "##### Hecho por: \n",
    "##### * Juan Sebastián Clavijo Martínez (jclavijomartinez@gmail.com) - PUJ - Ing. en redes y telecomunicaciones\n",
    "##### * Santiago Camacho (santiagocamachov@javeriana.edu.co ) - PUJ - Ing. de sistemas\n",
    "##### * Juan Pablo González (gonzalez-juanp@javeriana.edu.co) - PUJ - Ing. de sistemas <br />\n",
    "**Profesor: Jhon Corredor**<br />\n",
    "Fecha: 14-11-2023<br />\n",
    "Notas: <br />\n",
    "Dataset: Datos de nacimiento de los pueblos de antioquia y chocó del 2009 a 2019 obtenidos de la pagína del DANE e información sobre areas deforestadas en el chocó obtenido de datos.gov.co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "709f8002-c58a-4196-958f-d4364db4c444",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Se importan las bibliotecas pertinentes para el desarrollo del proyecto\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time ##Para medir rendimiento de los modelos\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c45a75b3-a296-4211-95a3-c8aaf9bb2ace",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Se crean dos dataframes, uno para cada set de datos. El primero corresponde al set de datos de areas deforestadas en el depaertamento del chocó en Colombia. El segundo corresponde a los datos de nacimiento de algunos municipios en Colombia. \n",
    "areas_deforestadas=pd.read_csv(\"https://raw.githubusercontent.com/jclavijomartinez/analiticaDeDatos2330/master/datos%20proyecto%20final/AREAS_DEFORESTADAS_CHOCO.csv\")\n",
    "# Para el dataframe de nacimientos se carga el archivo CSV especificando el delimitador como punto y coma ya que en el archivo CSV no se utiliza la coma como delimitador sino el ;\n",
    "nacimientos = pd.read_csv(\"https://raw.githubusercontent.com/jclavijomartinez/analiticaDeDatos2330/master/datos%20proyecto%20final/finaldatosnacimientos.csv\", sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97c9059b-ab47-4f7c-a4ff-e34455f4c31a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Se imprime la información del dataframe de areas deforestadas del chocó.\n",
    "areas_deforestadas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ca536d7-b898-4534-bdf3-9fecd5f37ef4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Se imprime la información del dataframde de nacimientos en los municipios del país.\n",
    "nacimientos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08c20805-c5a9-4290-84b5-47816994ce9c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### OBSERVACIÓN: Se evidencia que en ambos dataframes los valores de las columnas no son los mismos, lo que indica que hay datos duplicados y/o faltantes. A continuación se realizará la limpieza de los datasets teniendo como objetivo eliminar los dataos faltantes y los datos duplicados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c362468-688b-4f1c-8a4f-0518cc1a9dbc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##Cuenta de datas null, etc... para el dataframe de nacimientos     \n",
    "desaparecidos = len(nacimientos)-len(nacimientos.dropna())\n",
    "\n",
    "print('Cantidad de observaciones con Datos NaN', desaparecidos)\n",
    "print('Cantidad de datos duplicados', nacimientos.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0399768e-40c6-4250-b57e-0c8eb0c6a30a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##Cuenta de datas null, etc... para el dataframe de areas deforestadas\n",
    "desaparecidos = len(areas_deforestadas)-len(areas_deforestadas.dropna())\n",
    "\n",
    "print('Cantidad de observaciones con Datos NaN', desaparecidos)\n",
    "print('Cantidad de datos duplicados', areas_deforestadas.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9470dd05-675e-4681-b508-2760c1de1a8f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Se eliminan los datos Null y Duplicados para ambos dataframes\n",
    "areas_deforestadas.dropna(inplace=True)\n",
    "areas_deforestadas.drop_duplicates(inplace = True)\n",
    "nacimientos.dropna(inplace=True)\n",
    "nacimientos.drop_duplicates(inplace=True)\n",
    "#Se reinicia el indice por los eliminados (duplicados)\n",
    "areas_deforestadas.reset_index(drop = True, inplace = True)\n",
    "nacimientos.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5d15909-b006-4e19-b41a-078806daf246",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Se imprime la nueva información del dataset de nacimientos por municipio\n",
    "nacimientos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d733c1b-2569-4183-9fdc-dd24d8b7f391",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Se imprime la nueva información del dataset de areas deforestadas\n",
    "areas_deforestadas.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5331ed6a-af84-4ff3-8e0d-75068e4ffd07",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### OBSERVACIÓN: Se evidencia que se eliminaron los registros duplicados y valores faltantes para ambos datasets. Es decir, todas las columnas de ambos datasets tienen exactamente el mismo número de registros. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bf866e7-c89b-458f-8b97-f6157ef920bc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### nota: se cambiarán los nombres de algunas columnas de los datasets para que cumplan con el estándar PEP8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cef5366-6e81-4c8b-9fed-7be7ef9ee404",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Se cambian los nombres de ciertas columnas para que cumplan el estándar PEP8\n",
    "areas_deforestadas = areas_deforestadas.rename(columns={'TIPO GEOMETRIA': 'TIPO_GEOMETRIA'})\n",
    "nacimientos = nacimientos.rename(columns={'total H': 'total_H'})\n",
    "nacimientos = nacimientos.rename(columns={'total M': 'total_M'})\n",
    "nacimientos = nacimientos.rename(columns={'total indet': 'total_indet'})\n",
    "nacimientos = nacimientos.rename(columns={'cabecera municipal H': 'cabecera_municipal_H'})\n",
    "nacimientos = nacimientos.rename(columns={'cabecera municipal M': 'cabecera_municipal_M'})\n",
    "nacimientos = nacimientos.rename(columns={'cebecera municipal indet': 'cabecera_municipal_indet'})\n",
    "nacimientos = nacimientos.rename(columns={'centro poblado H': 'centro_poblado_H'})\n",
    "nacimientos = nacimientos.rename(columns={'centro poblado M': 'centro_poblado_M'})\n",
    "nacimientos = nacimientos.rename(columns={'centro poblado indet': 'centro_poblado_indet'})\n",
    "nacimientos = nacimientos.rename(columns={'rural disperso H': 'rural_disperso_H'})\n",
    "nacimientos = nacimientos.rename(columns={'rural disperso M': 'rural_disperso_M'})\n",
    "nacimientos = nacimientos.rename(columns={'rural disperso indet': 'rural_disperso_indet'})\n",
    "nacimientos = nacimientos.rename(columns={'sin info H': 'sin_info_H'})\n",
    "nacimientos = nacimientos.rename(columns={'sin info M': 'sin_info_M'})\n",
    "nacimientos = nacimientos.rename(columns={'sin info indet': 'sin_info_indet'})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaeb3ee4-9e21-4ca9-a8f5-e02d11957ede",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Se imprime la nueva información del dataset de areas deforestadas\n",
    "areas_deforestadas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16d4b068-2760-43aa-97db-c1877cc13c8b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Se imprime la nueva información del dataset de nacimientos\n",
    "nacimientos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22f78156-329f-41d6-ac29-baab3ef97f6f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Se imprimen los primeros 15 registros de cada dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "749de17b-66a7-4a54-addd-3239bf8cb4de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nacimientos.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bf8db0b-d742-45fd-b41d-d96f88e220dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "areas_deforestadas.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f23a9e17-93d2-46a2-8126-387891e467af",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ya que los dfs están listos para ser usados, \n",
    "# se crea uno nuevo con la información de los pueblos a ser evaluados, se va a usar primero arboles de desicion como modelo de ML, \n",
    "# se vizualiza la informacion del nuevo df con los datos refinados\n",
    "municipios_interes=['ZARAGOZA','NECHÍ','NÓVITA']\n",
    "df_seleccion = nacimientos[nacimientos['municipio'].isin(municipios_interes)]\n",
    "df_seleccion.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos las características y el objetivo\n",
    "caracteristicas = ['departamento', 'total_H', 'total_M', 'total_indet']\n",
    "objetivo = 'total'\n",
    "\n",
    "# Creamos el DataFrame con las características y el objetivo\n",
    "df_seleccion = df_seleccion[caracteristicas + [objetivo]]\n",
    "\n",
    "# Convertimos 'departamento' a números usando OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "df_seleccion['departamento'] = encoder.fit_transform(df_seleccion[['departamento']])\n",
    "\n",
    "# Se asignan características y objetivo\n",
    "X = df_seleccion[caracteristicas]\n",
    "y = df_seleccion[objetivo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos el conjunto en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo de árbol de decisión\n",
    "modelo_arbol = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "modelo_arbol.fit(X_train, y_train)\n",
    "\n",
    "# Reemplazamos las comas en la columna '0,00' y convertimos a float\n",
    "df_seleccion['0,00'] = df_seleccion['0,00'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Creamos el modelo de árbol de decisión\n",
    "modelo_arbol = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "modelo_arbol.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos predicciones en el conjunto de prueba\n",
    "predicciones = modelo_arbol.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, predicciones)\n",
    "print(f\"Precisión del modelo: {precision}\")\n",
    "\n",
    "# Mostramos la matriz de confusión\n",
    "matriz_confusion = confusion_matrix(y_test, predicciones)\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(matriz_confusion)\n",
    "\n",
    "# Mostramos el reporte de clasificación\n",
    "reporte_clasificacion = classification_report(y_test, predicciones)\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(reporte_clasificacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir una función de conversión\n",
    "def convertir_a_float(value):\n",
    "    try:\n",
    "        # Utilizar pd.to_numeric para manejar posibles errores de conversión\n",
    "        return pd.to_numeric(value.replace(',', '.'), errors='coerce')\n",
    "    except ValueError:\n",
    "        return np.nan  # Manejar errores de conversión como NaN\n",
    "\n",
    "# Aplicar la función a la columna 'total_H'\n",
    "nacimientos['total_H'] = nacimientos['total_H'].apply(convertir_a_float)\n",
    "\n",
    "# Manejar valores nulos después de la conversión\n",
    "nacimientos = nacimientos.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se dividen los datos en conjuntos de entrenamiento y prueba\n",
    "\n",
    "# Seleccionar características y variable dependiente\n",
    "X = nacimientos[['total_H', 'total_M', 'centro_poblado_H']]  \n",
    "y = nacimientos['total']  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para convertir y manejar comas\n",
    "# Función mejorada para convertir y manejar comas\n",
    "def convertir_a_float(valor):\n",
    "    try:\n",
    "        # Reemplazar comas y puntos al mismo tiempo\n",
    "        return float(str(valor).replace(',', '').replace('.', ''))\n",
    "    except ValueError:\n",
    "        return valor  # Si ya es un float, devolverlo sin cambios\n",
    "\n",
    "# Aplicar la función a las columnas relevantes\n",
    "nacimientos['total_H'] = nacimientos['total_H'].apply(convertir_a_float)\n",
    "nacimientos['total_M'] = nacimientos['total_M'].apply(convertir_a_float)\n",
    "nacimientos['centro_poblado_H'] = nacimientos['centro_poblado_H'].apply(convertir_a_float)\n",
    "nacimientos['total'] = nacimientos['total'].apply(convertir_a_float)\n",
    "\n",
    "# Manejar valores nulos después de la conversión\n",
    "nacimientos = nacimientos.dropna()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 610 entries, 336 to 102\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   total_H           610 non-null    float64\n",
      " 1   total_M           610 non-null    float64\n",
      " 2   centro_poblado_H  610 non-null    float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 19.1 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Mostrar información sobre las columnas de X_train\n",
    "print(X_train.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[70]: LinearRegression()"
     ]
    }
   ],
   "source": [
    "#Entrenar el modelo de regresión lineal múltiple\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error absoluto medio: 108.91797149938323\n",
      "Error cuadrático medio: 72754.75862586104\n",
      "Raíz cuadrada del error cuadrático medio: 269.7309003912252\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print('Error absoluto medio:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Error cuadrático medio:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Raíz cuadrada del error cuadrático medio:', metrics.mean_squared_error(y_test, y_pred)**0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "1. Error absoluto: El error absoluto es de aproximadamente 108.92. Esto significa que, en promedio, las predicciones del modelo tienen un error absoluto de alrededor de 108.92 unidades con respecto a los valores reales de la variable 'total'\n",
    "2. Error Cuadrático Medio: El error cuadrático medio es de aproximadamente 72754.76. Este valor indica que el modelo tiene un error cuadrático medio de alrededor de 72754.76 unidades al cuadrado con respecto a los valores reales. Es importante tener en cuenta que el MSE castiga más los errores grandes que el MAE.\n",
    "3. Raíz Cuadrada del Error Cuadrático Medio: La raíz cuadrada del error cuadrático medio  es de aproximadamente 269.73. Esta métrica es simplemente la raíz cuadrada del MSE y proporciona una medida de la dispersión de los errores. En este caso, el RMSE indica que, en promedio, las predicciones tienen un error de alrededor de 269.73 unidades con respecto a los valores reales.\n",
    "\n",
    "- Conclusión:\n",
    "\n",
    "  - El MAE de 108.92 sugiere que, en promedio, las predicciones están bastante cerca de los valores reales, pero aún hay margen para mejorar.\n",
    "\n",
    "  - El MSE de 72754.76 indica que hay algunos errores significativos en las predicciones, ya que los errores grandes tienen un impacto considerable en esta métrica.\n",
    "\n",
    "  - El RMSE de 269.73 proporciona una medida más interpretable del error y sugiere que, en promedio, las predicciones están a unos 269.73 unidades de los valores reales."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Proyecto Analítica Clavijo Camacho González",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
